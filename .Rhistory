library(rgdal)
library(sp)
data <- getData(name="worldclim", var="bio", res=10)
plot(data)
pak <- crop(data.extent(71.3671, 72.77246, 33.69406, 34.53423))
install.packages("rnaturalearth")
library(rnaturalearth)
pakistan_map <- rnaturalearth::ne_countries(country = "pakistan", returnclass = "sf")
# The precision has to be set to a value > 0 to resolve internal boundaries.
st_precision(Pakistan_map) <- 1e9 # Required to
pakistan_map <- st_union(pakistan_map)
{
par(mar = c(0,0,0,0))
plot(pakistan_map)
}
plot(data)
pak <- crop(pakistan_map)
pak <- crop(data, extent(pakistan_map))
plot(pak)
bio13 <- raster("bio13.asc")
#install.packages("raster")
#install.packages("rgdal")
library(raster)
library(rgdal)
library(sp)
library(rnaturalearth)
data <- getData(name="worldclim", var="bio", res=10)
pakistan_map <- rnaturalearth::ne_countries(country = "pakistan", returnclass = "sf")
# The precision has to be set to a value > 0 to resolve internal boundaries.
st_precision(Pakistan_map) <- 1e9 # Required to
pakistan_map <- st_union(pakistan_map)
{
par(mar = c(0,0,0,0))
plot(pakistan_map)
}
plot(data)
pak <- crop(data, extent(pakistan_map))
plot(pak)
#another
library(geodata)
MAPPP<-worldclim_country('tavg', res=10 ,path='/D:/R/')
MAPPP<-worldclim_country(var="tavg", res=10 ,path='/D:/R/')
MAPPP<-worldclim_country(var="tavg", country = "pakitan" res=10 ,path='/D:/R/')
MAPPP<-worldclim_country(var="tavg", country = "pakitan" ,path='/D:/R/')
MAPPP<-worldclim_country(var="tavg", country = "Pakitan" ,path='/D:/R/')
country_codes()
getOption("max.print")
country_codes()
getOption("max.print")
#another
library(geodata)
MAPPP<-worldclim_country(var="tavg", country = "Pakitan" ,path='/D:/R/')
MAPPP<-worldclim_country(var="tavg", country = "PAK" ,path='/D:/R/')
MAPPP<-worldclim_country(var="tavg", country = "PAK", path='D:/R/')
plot(MAPPP)
# if you dont want to download the whole world, use worldclim_tile() or worldclim_country()
pak<-crop(MAPPP,extent(pakistan_map))
# To focus on south America
plot(pak)
plot(pakistan_map)
install.packages("ConR")
install.packages("spm")
install.packages("SDMtune")
install.packages("pROC")
install.packages("swirl")
packageVersion("swirl")
library(swirl)
ls()
rm(list=ls())
rm(list=ls())
swirl()
install_from_swirl("Statistical Inference")
swirl()
packageVersion("swirl")
library(swirl)
ls()
rm(list=ls())
swirl()
myplot
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
z <- qnorm(.95)
pnorm(30+z, mean=30, lower.tail=FALSE)
pnorm(30+z, mean=32, lower.tail=FALSE)
pnorm(30+z, mean=32, sd=1, lower.tail=FALSE)
pnorm(30+z*2, mean=32, sd=2, lower.tail=FALSE)
power.t.test(n =
| 16, delta = 2 / 4, sd=1, type = "one.sample", alt = "one.sided")$power
power.t.test(n =16, delta = 2 / 4, sd=1, type = "one.sample", alt = "one.sided")$power
power.t.test(n =16, delta = 2, sd=4, type = "one.sample", alt = "one.sided")$power
power.t.test(n =16, delta = 100, sd=200, type = "one.sample", alt = "one.sided")$power
power.t.test(power = .8, delta = 2 / 4, sd=1, type = "one.sample", alt = "one.sided")$n
power.t.test(power = .8, delta = 2, sd=4, type = "one.sample", alt = "one.sided")$n
power.t.test(power = .8, delta = 100, sd=200, type = "one.sample", alt = "one.sided")$n
power.t.test(n =16, delta = 100, sd=200, type = "one.sample", alt = "one.sided")$power
Type power.t.test(power = .8, n=26, sd=1, type = "one.sample", alt = "one.sided")$delta
Type power.t.test(power = .8, n=26, sd=1, type = "one.sample", alt ="one.sided")$delta
power.t.test(power = .8, n=26, sd=1, type = "one.sample", alt ="one.sided")$delta
power.t.test(power = .8, n=27, sd=1, type = "one.sample", alt ="one.sided")$delta
library(swirl)
ls()
rm(list=ls())
swirl()
array(pValues)
head(pValues)
sum(<0.05)
sum(pValues<.05)
sum(p.adjust(pValues<.05, method = bonferroni))
sum(p.adjust(pValues,method="bonferroni") < 0.05)
sum(p.adjust(pValues,method="BH") < 0.05)
tail(trueStatus)
table(pValues2 < 0.05, trueStatus)
24/500
table(p.adjust(pValues2,method="bonferroni") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH") < 0.05, trueStatus)
sum(rep(1/6, 6) * seq(1:6))
print(g2)
head(sh)
nh
median(resampledMedians)
median(sh)
sam <- sample(fh, nh * B, replace = TRUE)
resam <- matrix(sam, B, nh)
meds <- apply(resam, 1, median)
median(meds) - median(fh)
sd(meds)
quantile(resampledMedians, c(.025, .975))
sd(resampledMedians)
quantile(resampledMedians, c(.025, .975))
quantile(meds, c(.025, .975))
dim(InsectSprays)
InsectSprays
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCcounts
group
testStat
obs <- testStat(BCcounts, group)
obs
mean(Bdata$count) - mean(Cdata$count)
sample(group)
perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))
mean(perms > obs)
testStat(DEcounts, group)
perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tinytex)
set.seed(2018)
lambda <- 0.2
n <- 40
sim_data <- replicate(1000, rexp(n, lambda))
mean_sim_data <- apply(sim_data, 2, mean)
# Sample Mean
sampleMean <- mean(mean_sim_data) # Mean of sample means
print (paste("Sample Mean = ", sampleMean))
# Theoretical Mean
# the expected mean of the exponential distribution of rate = 1/lambda
theoretical_mean <- (1/lambda)
print (paste("Theoretical Mean = ", theoretical_mean))
```
```{r}
# Histogram shows differences
hist(mean_sim_data, col="light blue", xlab = "Mean Average", main="Distribution of Exponential Average")
abline(v = theoretical_mean, col="brown")
abline(v = sampleMean, col="green")
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tinytex)
set.seed(2018)
set.seed(2024)
lambda <- 0.2
n <- 40
sim_data <- replicate(1000, rexp(n, lambda))
mean_sim_data <- apply(sim_data, 2, mean)
# Sample Mean
sampleMean <- mean(mean_sim_data) # Mean of sample means
print (paste("Sample Mean = ", sampleMean))
# Theoretical Mean
# the expected mean of the exponential distribution of rate = 1/lambda
theoretical_mean <- (1/lambda)
print (paste("Theoretical Mean = ", theoretical_mean))
# Histogram shows differences
hist(mean_sim_data, col="light blue", xlab = "Mean Average", main="Distribution of Exponential Average")
abline(v = theoretical_mean, col="brown")
abline(v = sampleMean, col="green")
# sample deviation & variance
sample_dev <- sd(mean_sim_data)
sample_dev
sample_variance <- sample_dev^2
sample_variance
# theoretical deviation & variance
theoretical_dev <- (1/lambda)/sqrt(n)
theoretical_dev
theoretical_variance <- ((1/lambda)*(1/sqrt(n)))^2
theoretical_variance
d<- data.frame(mean_sim_data)
t <- data.frame(theoretical_mean)
g <- ggplot(d, aes(x = mean_sim_data)) +
geom_histogram(binwidth = .2, color="black", fill="brown" , aes(y=..density..))+
stat_function(fun=dnorm, args=list(mean=theoretical_mean, sd=sd(mean_sim_data)),
color="green", size =1) +
stat_density(geom = "line", color = "blue", size =1)  +
labs(x="Mean", y= "Density",
title="Normal Distribution Comparision")
g
qqnorm(mean_sim_data)
qqline(mean_sim_data, col = "magenta")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tinytex)
set.seed(2024)
lambda <- 0.2
n <- 40
sim_data <- replicate(1000, rexp(n, lambda))
mean_sim_data <- apply(sim_data, 2, mean)
# Sample Mean
sampleMean <- mean(mean_sim_data) # Mean of sample means
print (paste("Sample Mean = ", sampleMean))
# Theoretical Mean
# the expected mean of the exponential distribution of rate = 1/lambda
theoretical_mean <- (1/lambda)
print (paste("Theoretical Mean = ", theoretical_mean))
# Histogram shows differences
hist(mean_sim_data, col="light blue", xlab = "Mean Average", main="Distribution of Exponential Average")
abline(v = theoretical_mean, col="brown")
abline(v = sampleMean, col="green")
# sample deviation & variance
sample_dev <- sd(mean_sim_data)
sample_dev
sample_variance <- sample_dev^2
sample_variance
# theoretical deviation & variance
theoretical_dev <- (1/lambda)/sqrt(n)
theoretical_dev
theoretical_variance <- ((1/lambda)*(1/sqrt(n)))^2
theoretical_variance
d<- data.frame(mean_sim_data)
t <- data.frame(theoretical_mean)
g <- ggplot(d, aes(x = mean_sim_data)) +
geom_histogram(binwidth = .2, color="black", fill="brown" , aes(y=..density..))+
stat_function(fun=dnorm, args=list(mean=theoretical_mean, sd=sd(mean_sim_data)),
color="green", size =1) +
stat_density(geom = "line", color = "blue", size =1)  +
labs(x="Mean", y= "Density",
title="Normal Distribution Comparision")
g
qqnorm(mean_sim_data)
qqline(mean_sim_data, col = "magenta")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tinytex)
set.seed(2024)
lambda <- 0.2
n <- 40
sim_data <- replicate(1000, rexp(n, lambda))
mean_sim_data <- apply(sim_data, 2, mean)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tinytex)
set.seed(2018)
lambda <- 0.2
n <- 40
sim_data <- replicate(1000, rexp(n, lambda))
mean_sim_data <- apply(sim_data, 2, mean)
# Sample Mean
sampleMean <- mean(mean_sim_data) # Mean of sample means
print (paste("Sample Mean = ", sampleMean))
# Theoretical Mean
# the expected mean of the exponential distribution of rate = 1/lambda
theoretical_mean <- (1/lambda)
print (paste("Theoretical Mean = ", theoretical_mean))
# Histogram shows differences
hist(mean_sim_data, col="light blue", xlab = "Mean Average", main="Distribution of Exponential Average")
abline(v = theoretical_mean, col="brown")
abline(v = sampleMean, col="green")
# sample deviation & variance
sample_dev <- sd(mean_sim_data)
sample_dev
sample_variance <- sample_dev^2
sample_variance
# theoretical deviation & variance
theoretical_dev <- (1/lambda)/sqrt(n)
theoretical_dev
theoretical_variance <- ((1/lambda)*(1/sqrt(n)))^2
theoretical_variance
d <- data.frame(mean_sim_data)
t <- data.frame(theoretical_mean)
g <- ggplot(d, aes(x = mean_sim_data)) +
geom_histogram(binwidth = .2, color="black", fill="brown" , aes(y=..density..))+
stat_function(fun=dnorm, args=list(mean=theoretical_mean, sd=sd(mean_sim_data)),
color="green", size =1) +
stat_density(geom = "line", color = "blue", size =1)  +
labs(x="Mean", y= "Density",
title="Normal Distribution Comparision")
g
d <- data.frame(mean_sim_data)
t <- data.frame(theoretical_mean)
g <- ggplot(d, aes(x = mean_sim_data)) +
geom_histogram(binwidth = .2, color="black", fill="brown" , aes(y=..density..))+
stat_function(fun=dnorm, args=list(mean=theoretical_mean, sd=sd(mean_sim_data)),
color="green", size =1) +
stat_density(geom = "line", color = "blue", size =1)  +
labs(x="Mean", y= "Density",
title="Normal Distribution Comparision")
g
d <- data.frame(mean_sim_data)
t <- data.frame(theoretical_mean)
g <- ggplot(d, aes(x = mean_sim_data)) +
geom_histogram(binwidth = .2, color="black", fill="brown" , aes(y=..density..))+
stat_function(fun=dnorm, args=list(mean=theoretical_mean, sd=sd(mean_sim_data)),
color="green", size =1) +
stat_density(geom = "line", color = "blue", size =1)  +
labs(x="Mean", y= "Density",
title="Normal Distribution Comparision")
g
qqnorm(mean_sim_data)
qqline(mean_sim_data, col = "magenta")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tinytex)
library(datasets)
data(ToothGrowth)
str(ToothGrowth)
head(ToothGrowth, 4)
tail(ToothGrowth, 4)
data(ToothGrowth)
str(ToothGrowth)
head(ToothGrowth, 4)
tail(ToothGrowth, 4)
summary(ToothGrowth)
# Calculatiing the mean of len based on the supplement methods
Supplement_mean = split(ToothGrowth$len, ToothGrowth$supp)
sapply(Supplement_mean, mean)
ggplot(aes(x=supp, y=len), data=ToothGrowth) + geom_boxplot(aes(fill=supp))+
xlab("Supplement Type") +ylab("Tooth length")
ggplot(aes(x=supp, y=len), data=ToothGrowth) + geom_boxplot(aes(fill=supp))+
xlab("Supplement Type") +ylab("Tooth length")
unique(ToothGrowth$dose)
g <- ggplot(aes(x = factor(dose), y = len), data = ToothGrowth) +
geom_boxplot(aes(fill = factor(dose)))
g <- g + labs(title="Tooth Lenght relationship to Dosage")
print(g)
t.test(len ~ supp, ToothGrowth[ToothGrowth$dose == .5, ])
t.test(len ~ supp, ToothGrowth[ToothGrowth$dose == 1, ])
t.test(len ~ supp, ToothGrowth[ToothGrowth$dose == 2, ])
library(swirl)
swirl()
install_from_swirl("Regression Models")
Introduction
For the first part of this course you should complete the following lessons:
Regression Models
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')]
abline(regrline, lwd=3, col='red')
summary(regrline)
regrline <- lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
View(fit)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals, galton$parent)
fit$coef
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
vh
ols.slope <- fit
lhs-rhs
all.equal(lhs,rhs)
varChild
var()
var(varChild)
var(ch, varChild)
cov(fit$residuals,galton$parent)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
---
title: "My_Project_2"
#### Executive Summary
This report analyzed the relationship between transmission type (manual or
```{r setup, include=FALSE}
```{r results='hide', message=FALSE}
library(ggplot2)
data(mtcars)
head(mtcars, n=3)
dim(mtcars)
library(ggplot2)
data(mtcars)
head(mtcars, n=3)
dim(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
attach(mtcars)
testResults <- t.test(mpg ~ am)
testResults$p.value
testResults$estimate
fullModelFit <- lm(mpg ~ ., data = mtcars)
summary(fullModelFit)  # results hidden
summary(fullModelFit)$coeff  # results hidden
stepFit <- step(fullModelFit)
summary(stepFit) # results hidden
summary(stepFit)$coeff # results hidden
sum((abs(dfbetas(stepFit)))>1)
boxplot(mpg ~ am,
xlab="Transmission Type (0 = Automatic, 1 = Manual)",
ylab="MPG",
main="MPG by Transmission Type")
par(mfrow = c(2, 2))
plot(stepFit)
set.seed(3523)
library(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
setwd("C:/Users/it computer world/Desktop/New Progress/Coursera/pml")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(caret)
gc()
trainRaw <- read.csv("pml-training.csv")
testRaw <- read.csv("pml-testing.csv")
dim(trainRaw)
dim(testRaw)
sum(complete.cases(trainRaw))
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
set.seed(22519) # For reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
stop("`data` and `reference` should be factors with the same levels.",
call. = FALSE)
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
predictRf <- predict(modelRf, testData)
stop("`data` and `reference` should be factors with the same levels.",
call. = FALSE)
predictRf <- predict(modelRf, testData)
confusionMatrix.default(testData$classe, predictRf)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
trainRaw <- read.csv("pml-training.csv")
testRaw <- read.csv("pml-testing.csv")
dim(trainRaw)
dim(testRaw)
sum(complete.cases(trainRaw))
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
set.seed(22519) # For reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
